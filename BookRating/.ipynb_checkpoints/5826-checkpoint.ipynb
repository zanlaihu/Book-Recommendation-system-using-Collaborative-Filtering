{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7f4785dac222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.float_format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os, gc, matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "warnings.filterwarnings('ignore'); np.set_printoptions(suppress=True); pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x); pd.options.display.max_rows = 15\n",
    "global directory; directory = '/'\n",
    "\n",
    "def files(): return os.listdir(directory)\n",
    "#Reading data\n",
    "def read_clean(data):\n",
    "    data.columns = [str(x.lower().strip().replace(' ','_')) for x in data.columns]\n",
    "    seen = {}; columns = []; i = 0\n",
    "    for i,x in enumerate(data.columns):\n",
    "        if x in seen: columns.append(x+'_{}'.format(i))\n",
    "        else: columns.append(x)\n",
    "        seen[x] = None\n",
    "        \n",
    "    for x in data.columns[data.count()/len(data) < 0.0001]: del data[x];\n",
    "    gc.collect();\n",
    "    try: data = data.replace({'':np.nan,' ':np.nan});\n",
    "    except: pass;\n",
    "    \n",
    "    if len(data) < 10000: l = len(data);\n",
    "    else: l = 10000;\n",
    "    sample = data.sample(l);size = len(sample);\n",
    "    \n",
    "    for x in sample.columns:\n",
    "        ints = pd.to_numeric(sample[x], downcast = 'integer', errors = 'coerce')\n",
    "        if ints.count()/size > 0.97:\n",
    "            minimum = ints.min()\n",
    "            if minimum > 0: data[x] = pd.to_numeric(data[x], downcast = 'unsigned', errors = 'coerce')\n",
    "            else: data[x] = pd.to_numeric(data[x], downcast = 'integer', errors = 'coerce')\n",
    "        else:\n",
    "            floats = pd.to_numeric(sample[x], downcast = 'float', errors = 'coerce')\n",
    "            if floats.count()/size > 0.97: data[x] = pd.to_numeric(data[x], downcast = 'float', errors = 'coerce')\n",
    "            else:\n",
    "                dates = pd.to_datetime(sample[x], errors = 'coerce')\n",
    "                if dates.count()/size > 0.97: data[x] = pd.to_datetime(data[x], errors = 'coerce')\n",
    "    return data.reset_index(drop = True)\n",
    "\n",
    "def read(x):\n",
    "    '''Kaggle Reading in CSV files.\n",
    "    Just type read('file.csv'), and you'll get back a Table.'''\n",
    "    \n",
    "    file = '{}/{}'.format(directory,x)\n",
    "    try:     data = pd.read_csv(file)\n",
    "    except:  data = pd.read_csv(file, encoding = 'latin-1')\n",
    "    return read_clean(data)\n",
    "\n",
    "## Plotting and Describeing Data\n",
    "def tally(column, minimum = 0, top = None, graph = False, percent = False, multiple = False, lowercase = False, min_count = 1):\n",
    "    '''Provides a tally count of all values in a COLUMN.\n",
    "        1. minimum  =  (>0)          Least count of item to show.\n",
    "        2. top      =  (-1,>0)       Only show top N objects\n",
    "        3. graph    =  (False,True)  Show bar graph of results\n",
    "        4. percent  =  (False,>0)    Instead of showing counts, show percentages of total count\n",
    "        \n",
    "       multiple = False/True.\n",
    "       If True, counts and tallies objects in list of lists (Count Vectorizer)\n",
    "       \n",
    "       lowercase = True / False.\n",
    "       If True, lowers all text firsrt. So A == a\n",
    "       \n",
    "       min_count >= 1\n",
    "       If a column sum for tag has less than min_count, discard whole column\n",
    "    '''\n",
    "    if multiple == False:\n",
    "        counts = column.value_counts().astype('uint')\n",
    "        counts = counts[counts >= minimum][:top]\n",
    "        counts = pd.DataFrame(counts).reset_index()\n",
    "        counts.columns = [column.name, 'tally']\n",
    "        if percent: \n",
    "            counts['tally'] /= counts['tally'].sum()/100\n",
    "            counts['tally'] = counts['tally']\n",
    "        if graph:\n",
    "            C = counts[::-1]\n",
    "            C.plot.barh(x = column.name, y = 'tally', legend = False); plt.show();\n",
    "        return counts\n",
    "    else:\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        column = column.fillna('<NAN>')\n",
    "        if type(column.iloc[0]) != list: column = column.apply(lambda x: [x])\n",
    "        counter = CountVectorizer(lowercase = lowercase, tokenizer = lambda x: x, dtype = np.uint32, min_df = min_count)\n",
    "        counter.fit(column)\n",
    "        counts = pd.DataFrame(counter.transform(column).toarray())\n",
    "        counts.columns = [column.name+'_('+str(x)+')' for x in counter.get_feature_names()]\n",
    "        return counts\n",
    "    \n",
    "    \n",
    "def describe(data):\n",
    "    '''Provides an overview of your data\n",
    "        1. dtype    =  Column type\n",
    "        2. missing% =  % of the column that is missing\n",
    "        3. nunique  =  Number of unique values in column\n",
    "        4. top3     =  Top 3 most occuring items\n",
    "        5. min      =  Minimum value. If not a number column, then empty\n",
    "        6. mean     =  Average value. If not a number column, then empty\n",
    "        7. median   =  Middle value. So sort all numbers, and get middle. If not a number column, then empty\n",
    "        8. max      =  Maximum value. If not a number column, then empty\n",
    "        9. sample   =  Random 2 elements\n",
    "        10. name    =  Column Name\n",
    "    '''\n",
    "    dtypes = dtype(data)\n",
    "    length = len(data)\n",
    "    missing = ((length - data.count())/length*100)\n",
    "    \n",
    "    N = [];    most3 = []\n",
    "    for dt,col in zip(dtypes,data.columns):\n",
    "        if dt != 'datetime':\n",
    "            U = data[col].value_counts()\n",
    "            N.append(len(U))\n",
    "            if U.values[0] > 1: most3.append(U.index[:3].tolist())\n",
    "            else: most3.append([]);\n",
    "        else: N.append(0); most3.append([]);\n",
    "            \n",
    "    df = pd.concat([dtypes, missing], 1)\n",
    "    df.columns = ['dtype','missing%']\n",
    "    df['nunique'] = N; df['top3'] = most3\n",
    "    \n",
    "    numbers = list(data.columns[df['dtype'].isin(('uint','int','float'))])\n",
    "    df['min'] = data.min()\n",
    "    df['mean'] = data[numbers].mean()\n",
    "    df['median'] = data[numbers].median()\n",
    "    df['max'] = data.max()\n",
    "    df['sample'] = data.apply(lambda x : x.sample(2).values.tolist())\n",
    "    df['name'] = list(data.columns)\n",
    "    return df.sort_values(['missing%', 'nunique', 'dtype'], ascending = [False, False, True]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "def Checker(x):\n",
    "    if type(x) is pd.DataFrame: return 0\n",
    "    elif type(x) is pd.Series: return 1\n",
    "    else: return -1\n",
    "\n",
    "def columns(data): return list(data.columns)\n",
    "def rows(data): return list(data.index)\n",
    "def index(data): return list(data.index)\n",
    "def head(data, n = 10): return data.head(n)\n",
    "def tail(data, n = 10): return data.tail(n)\n",
    "def sample(data, n = 10): return data.sample(n)\n",
    "\n",
    "def dtype(data):\n",
    "    what = Checker(data)\n",
    "    if what == 0:\n",
    "        dtypes = data.dtypes.astype('str')\n",
    "        dtypes = dtypes.str.split(r'\\d').str[0]\n",
    "    else:\n",
    "        dtypes = str(data.dtypes)\n",
    "        dtypes = re.split(r'\\d', dtypes)[0]\n",
    "    return dtypes\n",
    "\n",
    "def mean(data):\n",
    "    what = Checker(data)\n",
    "    _dt = ('uint','int','float')\n",
    "    if what == 0:\n",
    "        dtypes = dtype(data)\n",
    "        numbers = data.columns[dtypes.isin(_dt)]\n",
    "        return data[numbers].mean()\n",
    "    elif what == 1:\n",
    "        dtypes = dtype(data)\n",
    "        if dtypes in _dt: return data.mean()\n",
    "        else: return np.nan\n",
    "    else:\n",
    "        try:     return np.nanmean(data)\n",
    "        except:  return np.nan\n",
    "        \n",
    "def std(data):\n",
    "    what = Checker(data)\n",
    "    _dt = ('uint','int','float')\n",
    "    if what == 0:\n",
    "        dtypes = dtype(data)\n",
    "        numbers = data.columns[dtypes.isin(_dt)]\n",
    "        return data[numbers].std()\n",
    "    elif what == 1:\n",
    "        dtypes = dtype(data)\n",
    "        if dtypes in _dt: return data.std()\n",
    "        else: return np.nan\n",
    "    else:\n",
    "        try:     return np.nanstd(data)\n",
    "        except:  return np.nan\n",
    "        \n",
    "def var(data):\n",
    "    what = Checker(data)\n",
    "    _dt = ('uint','int','float')\n",
    "    if what == 0:\n",
    "        dtypes = dtype(data)\n",
    "        numbers = data.columns[dtypes.isin(_dt)]\n",
    "        return data[numbers].var()\n",
    "    elif what == 1:\n",
    "        dtypes = dtype(data)\n",
    "        if dtypes in _dt: return data.var()\n",
    "        else: return np.nan\n",
    "    else:\n",
    "        try:     return np.nanvar(data)\n",
    "        except:  return np.nan\n",
    "        \n",
    "def log(data):\n",
    "    what = Checker(data)\n",
    "    _dt = ('uint','int','float')\n",
    "    if what == 0:\n",
    "        dtypes = dtype(data)\n",
    "        numbers = data.columns[dtypes.isin(_dt)]\n",
    "        x = np.log(data[numbers])\n",
    "        x[np.isinf(x)] = np.nan\n",
    "        return pd.Series(x)\n",
    "    elif what == 1:\n",
    "        dtypes = dtype(data)\n",
    "        if dtypes in _dt:\n",
    "            x = np.log(data)\n",
    "            x[np.isinf(x)] = np.nan\n",
    "            return x\n",
    "        else: return np.nan\n",
    "    else:\n",
    "        try:\n",
    "            x = np.log(data)\n",
    "            x[np.isinf(x)] = np.nan\n",
    "            return x\n",
    "        except:  return np.nan\n",
    "        \n",
    "def median(data):\n",
    "    what = Checker(data)\n",
    "    _dt = ('uint','int','float')\n",
    "    if what == 0:\n",
    "        dtypes = dtype(data)\n",
    "        numbers = data.columns[dtypes.isin(_dt)]\n",
    "        return data[numbers].median()\n",
    "    elif what == 1:\n",
    "        dtypes = dtype(data)\n",
    "        if dtypes in _dt: return data.median()\n",
    "        else: return np.nan\n",
    "    else:\n",
    "        try:     return np.nanmedian(data)\n",
    "        except:  return np.nan\n",
    "        \n",
    "def minimum(data):\n",
    "    what = Checker(data)\n",
    "    if what == 0:      return data.min()\n",
    "    elif what == 1:    return data.min()\n",
    "    else:              return np.min(data)\n",
    "        \n",
    "def maximum(data):\n",
    "    what = Checker(data)\n",
    "    if what == 0:      return data.max()\n",
    "    elif what == 1:    return data.max()\n",
    "    else:              return np.max(data)\n",
    "    \n",
    "def missing(data):\n",
    "    what = Checker(data)\n",
    "    if what >= 0:      return pd.isnull(data)\n",
    "    else:              return np.isnan(data)\n",
    "    \n",
    "def count(data):\n",
    "    what = Checker(data)\n",
    "    if what >= 0:      return data.count()\n",
    "    else:              return len(data)\n",
    "    \n",
    "def nunique(data):\n",
    "    what = Checker(data)\n",
    "    if what >= 0:      return data.nunique()\n",
    "    else:              return len(np.unique(data))\n",
    "    \n",
    "def unique(data):\n",
    "    if type(data) is pd.DataFrame:\n",
    "        uniques = []\n",
    "        for x in data.columns:\n",
    "            uniques.append(data[x].unique())\n",
    "        df = pd.Series(uniques)\n",
    "        df.index = data.columns\n",
    "        return df\n",
    "    elif type(data) is pd.Series: return data.unique()\n",
    "    else:              return np.unique(data)\n",
    "    \n",
    "def total(data):\n",
    "    what = Checker(data)\n",
    "    _dt = ('uint','int','float')\n",
    "    if what == 0:\n",
    "        dtypes = dtype(data)\n",
    "        numbers = data.columns[dtypes.isin(_dt)]\n",
    "        return data[numbers].sum()\n",
    "    elif what == 1:\n",
    "        dtypes = dtype(data)\n",
    "        if dtypes in _dt: return data.sum()\n",
    "        else: return np.nan\n",
    "    else:\n",
    "        try:     return np.nansum(data)\n",
    "        except:  return np.nan\n",
    "        \n",
    "def time_number(date): return hours(date)+minutes(date)/60+seconds(date)/60**2\n",
    "def hours_minutes(date): return hours(date)+minutes(date)/60\n",
    "def hours(date): return date.dt.hour\n",
    "def minutes(date): return date.dt.minute\n",
    "def seconds(date): return date.dt.second\n",
    "def month(date): return date.dt.month\n",
    "def year(date): return date.dt.year\n",
    "def day(date): return date.dt.day\n",
    "def weekday(date): return date.dt.weekday\n",
    "def leap_year(date): return year(date).apply(calendar.isleap)\n",
    "def date_number(date): return year(date)+month(date)/12+day(date)/(365+leap_year(date)*1)\n",
    "def year_month(date): return year(date)+month(date)/12\n",
    "\n",
    "def hcat(*columns):\n",
    "    cols = []\n",
    "    for c in columns:\n",
    "        if c is None: continue;\n",
    "        if type(c) in (list, tuple): \n",
    "            for i in c:\n",
    "                if type(i) not in (pd.DataFrame, pd.Series): cols.append(pd.Series(i))\n",
    "                else: cols.append(i)\n",
    "        elif type(c) not in (pd.DataFrame, pd.Series): cols.append(pd.Series(c))\n",
    "        else: cols.append(c)\n",
    "    return pd.concat(cols, 1)\n",
    "\n",
    "def vcat(*columns):\n",
    "    cols = []\n",
    "    for c in columns:\n",
    "        if c is None: continue;\n",
    "        if type(c) in (list, tuple): \n",
    "            for i in c:\n",
    "                if type(i) not in (pd.DataFrame, pd.Series): cols.append(pd.Series(i))\n",
    "                else: cols.append(i)\n",
    "        elif type(c) not in (pd.DataFrame, pd.Series): cols.append(pd.Series(c))\n",
    "        else: cols.append(c)\n",
    "    return pd.concat(cols, 0)\n",
    "\n",
    "def melt(data, columns):\n",
    "    '''Converts a dataset into long form'''\n",
    "    return data.melt(id_vars = columns)\n",
    "    \n",
    "def tabulate(*columns, method = 'count'):\n",
    "    '''Splits columns into chunks, and counts the occurences in each group.\n",
    "        Remember - tabulate works on the LAST column passed.\n",
    "        Options:\n",
    "            1. count            = Pure Count in group\n",
    "            2. count_percent    = Percentage of Count in group\n",
    "            3. mean             = Mean in group\n",
    "            4. median           = Median in group\n",
    "            5. max              = Max in group\n",
    "            6. min              = Min in group\n",
    "            7. sum_percent      = Percentage of Sum in group\n",
    "        Eg:\n",
    "            Apple | 1\n",
    "            ---------\n",
    "            Orange| 3\n",
    "            ---------\n",
    "            Apple | 2\n",
    "            ---------\n",
    "        Becomes:\n",
    "            Apple | 1 | 1\n",
    "            -------------\n",
    "                  | 2 | 1\n",
    "            -------------\n",
    "            Orange| 3 | 1\n",
    "        \n",
    "        NOTE --------\n",
    "            method can be a list of multiple options.\n",
    "    '''\n",
    "    if type(method) in (list, tuple):\n",
    "        xs = []\n",
    "        for x in method:\n",
    "            g = tabulate(*columns, method = x)\n",
    "            xs.append(g)\n",
    "        xs = hcat(xs)\n",
    "        xs = xs.T.drop_duplicates().T\n",
    "        return read_clean(xs)        \n",
    "    else:\n",
    "        def percent(series):\n",
    "            counts = series.count()\n",
    "            return counts.sum()\n",
    "\n",
    "        data = hcat(*columns)\n",
    "        columns = data.columns.tolist()\n",
    "\n",
    "        if method in ('count', 'count_percent'):\n",
    "            groups = data.groupby(data.columns.tolist()).apply(lambda x: x[data.columns[-1]].count())\n",
    "\n",
    "            if method == 'count_percent':\n",
    "                groups = groups.reset_index()\n",
    "                groups.columns = list(groups.columns[:-1])+['Group_Count']\n",
    "                right = data.groupby(columns[:-1]).count().reset_index()\n",
    "                right.columns = list(right.columns[:-1])+['Group_Sum']\n",
    "\n",
    "                groups = pd.merge(left = groups, right = right, left_on = columns[:-1], right_on = columns[:-1])\n",
    "                groups['Percent%'] = groups['Group_Count']/groups['Group_Sum']*100\n",
    "                groups = groups[columns+['Percent%']]\n",
    "                return groups\n",
    "\n",
    "        elif method == 'mean': groups = data.groupby(data.columns.tolist()[:-1]).apply(lambda x: x[data.columns[-1]].mean())\n",
    "        elif method == 'median': groups = data.groupby(data.columns.tolist()[:-1]).apply(lambda x: x[data.columns[-1]].median())\n",
    "        elif method == 'max': groups = data.groupby(data.columns.tolist()[:-1]).apply(lambda x: x[data.columns[-1]].max())\n",
    "        elif method == 'min': groups = data.groupby(data.columns.tolist()[:-1]).apply(lambda x: x[data.columns[-1]].min())\n",
    "        elif method == 'sum_percent':\n",
    "            groups = data.groupby(data.columns.tolist()[:-1]).apply(lambda x: x[data.columns[-1]].sum()).reset_index()\n",
    "            groups.columns = list(groups.columns[:-1])+['Group_Count']\n",
    "            right = data.groupby(columns[:-1]).sum().reset_index()\n",
    "            right.columns = list(right.columns[:-1])+['Group_Sum']\n",
    "\n",
    "            groups = pd.merge(left = groups, right = right, left_on = columns[:-1], right_on = columns[:-1])\n",
    "            groups['Sum%'] = groups['Group_Count']/groups['Group_Sum']*100\n",
    "            groups = groups[cols+['Sum%']]\n",
    "            return groups\n",
    "        else:\n",
    "            print('Method does not exist. Please choose count, count_percent, mean, median, max, min, sum_percent.'); return None;\n",
    "        #except: print('Method = {}'.format(method)+' cannot work on Object, Non-Numerical data. Choose count.'); return None;\n",
    "\n",
    "        groups = pd.DataFrame(groups)\n",
    "        groups.columns = [method]\n",
    "        groups.reset_index(inplace = True)\n",
    "        return groups\n",
    "\n",
    "\n",
    "def sort(data, by = None, how = 'ascending', inplace = False):\n",
    "    ''' how can be 'ascending' or 'descending' or 'a' or 'd'\n",
    "    It can also be a list for each sorted column.\n",
    "    '''\n",
    "    replacer = {'ascending':True,'a':True,'descending':False,'d':False}\n",
    "    if by is None and type(data) is pd.Series:\n",
    "        try:    x = replacer[how]\n",
    "        except: print(\"how can be 'ascending' or 'descending' or 'a' or 'd'\"); return None;\n",
    "        return data.sort_values(ascending = x, inplace = inplace)\n",
    "    elif type(how) is not list:\n",
    "        try:    how = replacer[how]\n",
    "        except: print(\"how can be 'ascending' or 'descending' or 'a' or 'd'\"); return None;\n",
    "    else:\n",
    "        for x in how: \n",
    "            try:    x = replacer[x]\n",
    "            except: print(\"how can be 'ascending' or 'descending' or 'a' or 'd'\"); return None;\n",
    "    return data.sort_values(by, ascending = how, inplace = inplace)\n",
    "\n",
    "def keep(data, what, inplace = False):\n",
    "    '''Keeps data in a column if it's wanted.\n",
    "    Everything else is filled with NANs'''\n",
    "    if type(what) not in (list,tuple,np.array,np.ndarray): what = [what]\n",
    "    need = data.isin(what)\n",
    "    if inplace: \n",
    "        df = data\n",
    "        df.loc[~need] = np.nan\n",
    "    else: \n",
    "        df = data.copy()\n",
    "        df.loc[~need] = np.nan\n",
    "        return df\n",
    "\n",
    "def remove(data, what, inplace = False):\n",
    "    '''Deletes data in a column if it's not wanted.\n",
    "    Everything else is filled with NANs'''\n",
    "    if type(what) not in (list,tuple): what = [what]\n",
    "    need = data.isin(what)\n",
    "    if inplace: \n",
    "        df = data\n",
    "        df.loc[need] = np.nan\n",
    "    else: \n",
    "        df = data.copy()\n",
    "        df.loc[need] = np.nan\n",
    "        return df\n",
    "    \n",
    "    \n",
    "def ternary(data, condition, true, false = np.nan, inplace = False):\n",
    "    '''C style ternary operator on column.\n",
    "    Condition executes on column, and if true, is filled with some value.\n",
    "    If false, then replaced with other value. Default false is NAN.'''\n",
    "    try:\n",
    "        execute = 'data {}'.format(condition)\n",
    "        series = eval(execute)\n",
    "        try: series = series.map({True:true, False:false})\n",
    "        except: series = series.replace({True:true, False:false})\n",
    "        return series\n",
    "    except: print('Ternary accepts conditions where strings must be enclosed.\\nSo == USD not allowed. == \"USD\" allowed.'); return False;\n",
    "\n",
    "    \n",
    "def locate(data, column):\n",
    "    '''Use ternary to get result and then filter with notnull'''\n",
    "    if dtype(column) == 'bool': return data.loc[column]\n",
    "    return data.loc[column.notnull()]\n",
    "    \n",
    "    \n",
    "def query(data, column = None, condition = None):\n",
    "    '''Querying data based on conditions'''\n",
    "    if type(column) is str:\n",
    "        cond = f'data[\"{column}\"]{condition}'\n",
    "    else:\n",
    "        cond = f'column{condition}'\n",
    "    return data.loc[eval(cond)]\n",
    "\n",
    "\n",
    "def keep_top(x, n = 5):\n",
    "    '''Keeps top n (after tallying) in a column'''\n",
    "    df = keep(x, tally(x)[x.name][:n].values)\n",
    "    return df\n",
    "\n",
    "def keep_bot(x, n = 5):\n",
    "    '''Keeps bottom n (after tallying) in a column'''\n",
    "    df = keep(x, tally(x)[x.name][:-n].values)\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_outlier(x, method = 'iqr', range = 1.5):\n",
    "    '''Removes outliers in column with methods:\n",
    "        1. mean     =    meean+range (normally 3.5)\n",
    "        2. median   =    median+range (normally 3.5)\n",
    "        3. iqr      =    iqr+range (normally 1.5)\n",
    "    '''\n",
    "    i = x.copy()\n",
    "    if method == 'iqr':\n",
    "        first = np.nanpercentile(x, 0.25)\n",
    "        third = np.nanpercentile(x, 0.75)\n",
    "        iqr = third-first\n",
    "        i[(i > third+iqr*range) | (i < first-iqr*range)] = np.nan\n",
    "    else:\n",
    "        if method == 'mean': mu = np.nanmean(x)\n",
    "        else: mu = np.nanmedian(x)\n",
    "        std = np.nanstd(x)\n",
    "        i[(i > mu+std*range) | (i < mu-std*range)] = np.nan\n",
    "    return i\n",
    "\n",
    "\n",
    "def cut(x, bins = 5, method = 'range'):\n",
    "    '''Cut continuous column into parts.\n",
    "        Method options:\n",
    "            1. range\n",
    "            2. quantile (number of quantile cuts)'''\n",
    "    if method == 'range': return pd.cut(x, bins = bins, duplicates = 'drop')\n",
    "    else: return pd.qcut(x, q = bins, duplicates = 'drop')\n",
    "    \n",
    "    \n",
    "def plot(x, y = None, colour = None, column = None, data = None, size = 5, top = 10, wrap = 4, \n",
    "         subset = 5000, method = 'mean', quantile = True, bins = 10,\n",
    "         style = 'lineplot', logx = False, logy = False, logc = False, power = 1):\n",
    "    '''Plotting function using seaborn and matplotlib\n",
    "        Options:\n",
    "        x, y, colour, column, subset, style, method\n",
    "        \n",
    "        Plot styles:\n",
    "            1. boxplot\n",
    "            2. barplot\n",
    "            3. tallyplot (counting number of appearances)\n",
    "            4. violinplot (boxplot just fancier)\n",
    "            5. lineplot (mean line plot)\n",
    "            6. histogram\n",
    "            7. scatterplot (X, Y must be numeric --> dates will be converted)\n",
    "            8. bivariate (X, Y must be numeric --> dates will be converted)\n",
    "            9. heatmap (X, Y will be converted into categorical automatically --> bins)\n",
    "            10. regplot (X, Y must be numeric --> dates will be converted)\n",
    "    '''\n",
    "    if type(x) in (np.array,np.ndarray): x = pd.Series(x); x.name = 'x';\n",
    "    if type(y) in (np.array,np.ndarray): y = pd.Series(y); y.name = 'y';\n",
    "    if type(column) in (np.array,np.ndarray): column = pd.Series(column); column.name = 'column';\n",
    "    if type(colour) in (np.array,np.ndarray): colour = pd.Series(colour); colour.name = 'colour';\n",
    "        \n",
    "    if type(x) == pd.Series: \n",
    "        data = pd.DataFrame(x); x = x.name\n",
    "        if type(x) is not str:\n",
    "            data.columns = [str(x)]\n",
    "            x = str(x)\n",
    "    if method == 'mean': estimator = np.nanmean\n",
    "    elif method == 'median': estimator = np.nanmedian\n",
    "    elif method == 'min': estimator = np.min\n",
    "    elif method == 'max': estimator = np.max\n",
    "    else: print('Wrong method. Allowed = mean, median, min, max'); return False;\n",
    "    #----------------------------------------------------------\n",
    "    sb.set(rc={'figure.figsize':(size*1.75,size)})\n",
    "    dtypes = {'x':None,'y':None,'c':None,'col':None}\n",
    "    names = {'x':None,'y':None,'c':None,'col':None}\n",
    "    xlim = None\n",
    "    #----------------------------------------------------------\n",
    "    if data is not None:\n",
    "        if type(x) is str: x = data[x];\n",
    "        if type(y) is str: y = data[y]; \n",
    "        if type(colour) is str: colour = data[colour]; \n",
    "        if type(column) is str: column = data[column]; \n",
    "    if type(x) is str: print('Please specify data.'); return False;\n",
    "    #----------------------------------------------------------\n",
    "    if x is not None:\n",
    "        dtypes['x'] = dtype(x); names['x'] = x.name\n",
    "        if dtypes['x'] == 'object': x = keep_top(x, n = top)\n",
    "        elif dtypes['x'] == 'datetime': x = date_number(x)\n",
    "        if logx and dtype(x) != 'object': x = log(x)\n",
    "    if y is not None: \n",
    "        dtypes['y'] = dtype(y); names['y'] = y.name\n",
    "        if dtypes['y'] == 'object': y = keep_top(y, n = top)\n",
    "        elif dtypes['y'] == 'datetime': y = date_number(y)\n",
    "        if logy and dtype(y) != 'object': y = log(y)\n",
    "    if colour is not None:\n",
    "        dtypes['c'] = dtype(colour); names['c'] = colour.name\n",
    "        if dtypes['c'] == 'object': colour = keep_top(colour, n = top)\n",
    "        elif dtypes['c'] == 'datetime': colour = date_number(colour)\n",
    "        if logc and dtype(colour) != 'object': colour = log(colour)\n",
    "    if column is not None:\n",
    "        dtypes['col'] = dtype(column); names['col'] = column.name\n",
    "        if dtypes['col'] == 'object': column = keep_top(column, n = top)\n",
    "        elif dtypes['col'] == 'datetime': column = date_number(column)\n",
    "    #----------------------------------------------------------\n",
    "    df = hcat(x, y, colour, column)\n",
    "    if subset > len(df): subset = len(df)\n",
    "    df = sample(df, subset)\n",
    "    #----------------------------------------------------------\n",
    "    if column is not None:\n",
    "        if dtype(df[names['col']]) not in ('object', 'uint',' int') and nunique(df[names['col']]) > top: \n",
    "            if quantile: df[names['col']] = cut(df[names['col']], bins = bins, method = 'quantile')\n",
    "            else: df[names['col']] = cut(df[names['col']], bins = bins, method = 'range')\n",
    "    \n",
    "    try: df.sort_values(names['y'], inplace = True);\n",
    "    except: pass;\n",
    "    #----------------------------------------------------------\n",
    "    replace = {'boxplot':'box', 'barplot':'bar', 'tallyplot':'count', 'violinplot':'violin', \n",
    "               'lineplot': 'point', 'histogram':'lv'}\n",
    "    \n",
    "    if style == 'histogram' and y is None:\n",
    "        plot = sb.distplot(df[names['x']].loc[df[names['x']].notnull()], bins = bins)\n",
    "    elif style == 'lineplot' and y is None:\n",
    "        plot = plt.plot(df[names['x']]);\n",
    "        plt.show(); return;\n",
    "    elif style == 'barplot' and y is None:\n",
    "        plot = df.sort_values(names['x']).plot.bar();\n",
    "        plt.show(); return;\n",
    "    elif style in replace.keys():\n",
    "        if dtype(df[names['x']]) not in ('object', 'uint',' int') and nunique(df[names['x']]) > top: \n",
    "            if quantile: df[names['x']] = cut(df[names['x']], bins = bins, method = 'quantile')\n",
    "            else: df[names['x']] = cut(df[names['x']], bins = bins, method = 'range')\n",
    "        \n",
    "        if names['col'] is not None:\n",
    "            plot = sb.factorplot(x = names['x'], y = names['y'], hue = names['c'], data = df, kind = replace[style], col = names['col'],\n",
    "                             n_boot = 1, size = size, estimator = estimator, col_wrap = wrap)\n",
    "        else:\n",
    "            plot = sb.factorplot(x = names['x'], y = names['y'], hue = names['c'], data = df, kind = replace[style], col = names['col'],\n",
    "                             n_boot = 1, size = size, estimator = estimator)\n",
    "            \n",
    "        for ax in plot.axes.flatten(): \n",
    "            for tick in ax.get_xticklabels(): \n",
    "                tick.set(rotation=90)\n",
    "    \n",
    "    elif style == 'heatmap':\n",
    "        if dtype(df[names['x']]) != 'object'and nunique(df[names['x']]) > top:\n",
    "            if quantile: df[names['x']] = cut(df[names['x']], bins = bins, method = 'quantile')\n",
    "            else: df[names['x']] = cut(df[names['x']], bins = bins, method = 'range')\n",
    "                \n",
    "        if dtype(df[names['y']]) != 'object'and nunique(df[names['y']]) > top:\n",
    "            if quantile: df[names['y']] = cut(df[names['y']], bins = bins, method = 'quantile')\n",
    "            else: df[names['y']] = cut(df[names['y']], bins = bins, method = 'range')     \n",
    "\n",
    "        df = tabulate(df[names['x']], df[names['y']]).pivot(index = names['x'], columns = names['y'], values = 'count')\n",
    "        plot = sb.heatmap(df, cmap=\"YlGnBu\")\n",
    "\n",
    "        \n",
    "    elif dtype(df[names['x']]) == 'object' or dtype(df[names['y']]) == 'object':\n",
    "            print('{} can only take X = number and Y = number.'.format(style)); return False;\n",
    "        \n",
    "    elif style  in ('regplot', 'scatterplot'):\n",
    "        if column is None: col_wrap = None\n",
    "        else: col_wrap = wrap\n",
    "        if style == 'regplot': reg = True\n",
    "        else: reg = False\n",
    "        \n",
    "        plot = sb.lmplot(x = names['x'], y = names['y'], hue = names['c'], data = df, col = names['col'],\n",
    "                             n_boot = 2, size = size, ci = None, scatter_kws={\"s\": 50,'alpha':0.5},\n",
    "                        col_wrap = col_wrap, truncate = True, fit_reg = reg, order = power)\n",
    "        plot.set_xticklabels(rotation=90)\n",
    "        \n",
    "    elif style == 'bivariate':\n",
    "        plot = sb.jointplot(x = names['x'], y = names['y'], data = df, dropna = True, size = size, kind = 'reg',\n",
    "                           scatter_kws={\"s\": 50,'alpha':0.5}, space = 0)\n",
    "    plt.show()\n",
    "    \n",
    "def remove(x, what):\n",
    "    return replace(x, what, '')\n",
    "    \n",
    "def notnull(data, loc = None):\n",
    "    '''Returns the items that are not null in a column / dataframe'''\n",
    "    if loc is not None:\n",
    "        return data.loc[loc.notnull()]\n",
    "    else:\n",
    "        return data.loc[data.notnull().sum(1) == data.shape[1]]\n",
    "    \n",
    "    \n",
    "def exclude(data, col):\n",
    "    '''Only returns a dataframe where the columns in col are not included'''\n",
    "    if type(col) is str: col = [col]\n",
    "    columns = list(data.columns)\n",
    "    leave = list(set(columns) - set(col))\n",
    "    return data[leave]\n",
    "\n",
    "################### -----------------------------------------------------------------#######################\n",
    "#Recommendation Systems\n",
    "def pivot(index, columns, values):\n",
    "    '''Creates a table where rows = users, columns = items, and cells = values / ratings'''\n",
    "    from scipy.sparse import dok_matrix\n",
    "    S = dok_matrix((nunique(index), nunique(columns)), dtype=np.float32)\n",
    "    \n",
    "    mins = np.abs(np.min(values))+1\n",
    "    indexM = {}\n",
    "    for i,x in enumerate(unique(index)): indexM[x] = i;\n",
    "    columnsM = {}\n",
    "    for i,x in enumerate(unique(columns)): columnsM[x] = i;\n",
    "        \n",
    "    for i,c,v in zip(index, columns, values+mins): S[indexM[i],columnsM[c]] = v;\n",
    "    \n",
    "    S = S.toarray(); S[S == 0] = np.nan; S -= mins\n",
    "    S = pd.DataFrame(S)\n",
    "    S.index = indexM.keys(); S.columns = columnsM.keys();\n",
    "    return S\n",
    "\n",
    "def row_operation(data, method = 'sum'):\n",
    "    '''Apply a function to a row\n",
    "        Allowed functions:\n",
    "            1. sum\n",
    "            2. median\n",
    "            3. mean\n",
    "            4. max\n",
    "            5. min\n",
    "            6. count\n",
    "            7. count_percent\n",
    "            8. sum_percent\n",
    "            9. mean_zero         (Mean but zeroes arent counted)\n",
    "            10. count_zero       (Count but zeroes arent counted)\n",
    "        Own functions are also allowed.\n",
    "    '''\n",
    "    if method in ('sum','median','mean','max','min','count'):\n",
    "        x = eval('data.{}(1)'.format(method))\n",
    "    elif method in ('count_percent', 'sum_percent'):\n",
    "        x = eval('data.{}(1)'.format(method.split('_')[0]))\n",
    "        x /= x.sum()\n",
    "        x *= 100\n",
    "    elif method in ('mean_zero', 'count_zero'):\n",
    "        df = data.copy()\n",
    "        df[df == 0] = np.nan\n",
    "        x = eval('df.{}(1)'.format(method.split('_')[0]))\n",
    "    else: return data.apply(method, axis = 1)\n",
    "    x.name = 'row_operation'\n",
    "    return x\n",
    "\n",
    "\n",
    "def col_operation(data, method = 'sum'):\n",
    "    '''Apply a function to a column\n",
    "        Allowed functions:\n",
    "            1. sum\n",
    "            2. median\n",
    "            3. mean\n",
    "            4. max\n",
    "            5. min\n",
    "            6. count\n",
    "            7. count_percent\n",
    "            8. sum_percent\n",
    "            9. mean_zero         (Mean but zeroes arent counted)\n",
    "            10. count_zero       (Count but zeroes arent counted)\n",
    "        Own functions are also allowed.\n",
    "        '''\n",
    "    if method in ('sum','median','mean','max','min','count'):\n",
    "        x = eval('data.{}(0)'.format(method))\n",
    "    elif method in ('count_percent', 'sum_percent'):\n",
    "        x = eval('data.{}(0)'.format(method.split('_')[0]))\n",
    "        x /= x.sum()\n",
    "        x *= 100\n",
    "    elif method in ('mean_zero', 'count_zero'):\n",
    "        df = data.copy()\n",
    "        df[df == 0] = np.nan\n",
    "        x = eval('df.{}(0)'.format(method.split('_')[0]))\n",
    "    else: return data.apply(method, axis = 0)\n",
    "    x.name = 'col_operation'\n",
    "    return x\n",
    "\n",
    "    \n",
    "def random(obj, n = 1, p = None):\n",
    "    if p is not None:\n",
    "        if type(p) is pd.Series: p = p.values\n",
    "        if p.sum() > 2: p /= 100\n",
    "    return list(np.random.choice(obj, size = n, replace = False, p = p))\n",
    "\n",
    "def row(data, n): return data.loc[n]\n",
    "\n",
    "def distances(source, target):\n",
    "    '''Returns all distances between target and source (L2)'''\n",
    "    Y = np.tile(target.values, (source.shape[0],1))\n",
    "    nans = np.isnan(Y)\n",
    "    X = source.values; X[np.isnan(X)] = 0;\n",
    "    Y[nans] = 0;\n",
    "    diff = X - Y;\n",
    "    diff[nans] = 0;\n",
    "    d = np.linalg.norm(diff, axis = 1)\n",
    "    j = pd.Series(d)\n",
    "    j.index = source.index\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-58acd131bc36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
